{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "CGCV192013B.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87t9m7vdFL6G",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "SOW-MKI95 Computer Graphics & Computer Vision Spring 2020\n",
        "Dr. Umut Güçlü\n",
        "Lab 13: Variational autoencoders\n",
        "05-06-2020\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTiJBPQyFPOk",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Group number: ...\n",
        "Student 1 name/number: ...\n",
        "Student 2 name/number: ...\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSl_faq2EGYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet import autograd, nd, gluon\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Feel free to import other modules/packages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izULJfhWEGYg",
        "colab_type": "text"
      },
      "source": [
        "### Task 1 (10 points):\n",
        "\n",
        "* Implement the decoder class for a variational autoencoder.\n",
        "\n",
        "---o---\n",
        "\n",
        "Recall that the decoder transforms latents (features) to observables (images). It corresponds to p(x | z) in the context of variational inference (and the slides), where x is observables and z is latents. Note that it should output the Gaussian parameters (mean and variance per pixel) of images rather than images themselves.\n",
        "\n",
        "---o---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEDrnNpjEGYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.HybridSequential):\n",
        "    def __init__(self, activation = \"relu\", hiddens = 400, observables = 784, layers = 1, **kwargs): # Feel free to use different arguments\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        # Your code here..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KE1zoq2EGYk",
        "colab_type": "text"
      },
      "source": [
        "### Task 2 (10 points):\n",
        "\n",
        "* Implement the encoder class for a variational autoencoder.\n",
        "\n",
        "---o---\n",
        "\n",
        "Recall that the encoder transforms observables (images) to latents (features). It corresponds to q(z | x) in the context of variational inference (and the slides), where z is latents and x is observables. Note that it should output the Gaussian parameters (mean and variance per feature) of features rather than features themselves.\n",
        "\n",
        "---o---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sZngO1pEGYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.HybridSequential):\n",
        "    def __init__(self, activation = \"relu\", hiddens= 400, latents = 2, layers = 1, **kwargs): # Feel free to use different arguments\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        # Your code here..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N59f0FCOEGYn",
        "colab_type": "text"
      },
      "source": [
        "### Task:\n",
        "\n",
        "* Implement the loss function class for a variational autoecoder.\n",
        "\n",
        "---o---\n",
        "\n",
        "The loss function takes the following arguments as input:\n",
        "\n",
        "* x        : input images (mini batch)\n",
        "* x_mean   : mean of the decoded images (output of the decoder)\n",
        "* x_log_var: mean of the decoded images (output of the decoder)\n",
        "* z_mean   : mean of the encoded features (output of the encoder)\n",
        "* z_log_var: log variance of the encoded features (output of the encoder)\n",
        "\n",
        "It gives the following evidence lower bound (ELBO) as ouput:\n",
        "\n",
        "* $L = D_{KL}(q(z | x), p(z)) -  E_{z\\sim q}[log p(x | z)]$\n",
        "\n",
        "where\n",
        "\n",
        "* The first term is the KL divergence between the approximate Gaussian posterior (q) and the standard Gaussian prior (p), which can be interpreted as a form of regularization.\n",
        "* The second term is the Gaussian negative log likelihood, which is the term that fits the data and is very similar to the usual loss functions that are usded in deep learning.\n",
        "\n",
        "---o---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAfVRFXJEGYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lossfun:\n",
        "    def __init__(self, w = 1.0): # Feel free to use different w which can be used as the weight of the different loss components\n",
        "        self.w = w\n",
        "\n",
        "    def __call__(self, x, x_mean, x_log_var, z_mean, z_log_var):\n",
        "        # Your code here..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gxKE99gEGYr",
        "colab_type": "text"
      },
      "source": [
        "### Task (5 points):\n",
        "\n",
        "* Implement the variational autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esbwnvO4EGYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder(gluon.HybridBlock):\n",
        "    def __init__(self,  activation = \"relu\", hiddens= 400, latents = 2, observables = 784, layers = 1, **kwargs): # Feel free to use different arguments\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        with self.name_scope():\n",
        "            self.decoder = Encoder(activation, hiddens, observables, layers, **kwargs)\n",
        "            self.encoder = Encoder(activation, hiddens, latents, layers, **kwargs)\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        # Your code here...\n",
        "\n",
        "        return x_mean, x_log_var, z_mean, z_log_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjFitH3uEGYu",
        "colab_type": "text"
      },
      "source": [
        "### Task (25 points):\n",
        "\n",
        "* Train the variational autoencoder on the Mnist dataset. You can refer to the previous assignment to implement your training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vunmTd11EGYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er_NwFS0EGYy",
        "colab_type": "text"
      },
      "source": [
        "### Task (50 points):\n",
        "* Evaluate the reconstruction quality of the variational autoencoder: Draw some Mnist like images, encode them, decode them, visualize them and briefly explain the results.\n",
        " * Repeat the task with drawings of something else (e.g., a face).\n",
        "* Evaluate the sampling quality of the variational autoencoder: Sample some random features from the prior, decode them, visualize them and briefly explain the results.\n",
        " * Repeat the task with features on a regular grid.\n",
        "* Evaluate the latent quality of the variational autoencoder: Scatter plot features of images, color code their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1SGUbpfEGYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here..."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}